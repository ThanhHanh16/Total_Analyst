{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0c5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file gốc\n",
    "excel_path = \"data_cleaned.xlsx\"\n",
    "df = pd.read_excel(excel_path, sheet_name= 'customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb147dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DOB'] = pd.to_datetime(df['DOB'], origin='1899-12-30', unit='D', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfc7e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DOB\n",
      "0 1999-04-18\n",
      "1 1998-04-16\n",
      "2 1993-12-16\n",
      "3 1999-11-08\n",
      "4 1994-10-01\n"
     ]
    }
   ],
   "source": [
    "print(df[['DOB']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe539f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid          0\n",
       "DOB                 0\n",
       "gender              0\n",
       "address             1\n",
       "job                 0\n",
       "industry         1122\n",
       "year_of_birth       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = ['gender', 'address','website', 'job', 'industry']\n",
    "for col in string_columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Website'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda92ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_of_birth'] = df['DOB'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88897c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tìm năm sinh phổ biến nhất theo job\n",
    "most_common_year_by_job = {}\n",
    "for job in df['job'].dropna().unique():\n",
    "    subset = df[(df['job'] == job) & (df['year_of_birth'].notna())]['year_of_birth']\n",
    "    if not subset.empty:\n",
    "        mode_year = subset.mode()\n",
    "        if not mode_year.empty:\n",
    "            most_common_year_by_job[job] = int(mode_year[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d2e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm điền DOB bị thiếu\n",
    "def fill_missing_dob(row):\n",
    "    if pd.isna(row['DOB']):\n",
    "        job = row['job']\n",
    "        if job in most_common_year_by_job:\n",
    "            year = most_common_year_by_job[job]\n",
    "            return pd.Timestamp(f'{year}-01-01')\n",
    "    return row['DOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b72f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Áp dụng hàm để điền DOB\n",
    "df['DOB'] = df.apply(fill_missing_dob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a16d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Cập nhật lại year_of_birth sau khi đã điền thêm DOB\n",
    "df['year_of_birth'] = df['DOB'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6beb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid       0\n",
       "DOB              0\n",
       "gender           0\n",
       "address          0\n",
       "job              0\n",
       "industry         0\n",
       "year_of_birth    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cae6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "film = pd.read_excel(excel_path, sheet_name = \"film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e4e8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_id          0\n",
       "title            0\n",
       "director        10\n",
       "cast             6\n",
       "country          7\n",
       "release_year     0\n",
       "rating           1\n",
       "duration         0\n",
       "listed_in        0\n",
       "description      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1e41b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# làm sạch dữ liệu cột desciption cà cast của film\n",
    "from ftfy import fix_text\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = fix_text(text)  # Sửa lỗi mã hóa\n",
    "        for ch in ['“', '”', '\"', \"'\"]:\n",
    "            text = text.replace(ch, '')  # Bỏ dấu ngoặc kép\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# Áp dụng cho các cột\n",
    "film['description'] = film['description'].apply(clean_text)\n",
    "film['cast'] = film['cast'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee09c1",
   "metadata": {},
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c198e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James McAvoy, Michael Fassbender, Jennifer Law...</td>\n",
       "      <td>When Jean Grey transforms into the Dark Phoeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louis Ashbourne Serkis, Tom Taylor, Rebecca Fe...</td>\n",
       "      <td>When a kid discovers the legendary sword, Exca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a-chan , KASHIYUKA , NOCCHi</td>\n",
       "      <td>J-Pop band Perfume shares their passion for mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOSHIKI</td>\n",
       "      <td>Yoshiki from X Japan performs two Disney songs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dan Nachtrab</td>\n",
       "      <td>Great Shark Chow Down – prepare for a feast of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jeremiah Sullivan, Dave Hoffman</td>\n",
       "      <td>Marine biologist attempts to get bitten by a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bert Morris</td>\n",
       "      <td>Discover the technical prowess behind Petra, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jay Sanders</td>\n",
       "      <td>National Geographic reconstructs the Ulfberht,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maite Jauregui</td>\n",
       "      <td>Forensic experts scan Pompeiis victims to inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Loïck Peyron</td>\n",
       "      <td>Loïck Peyron investigates the 1978 Amoco Cadiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Colin Solman</td>\n",
       "      <td>As we follow the robbers life cycle, we learn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Paul Bandey</td>\n",
       "      <td>On April 15, 2019, Paris firefighters gave eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Neil Harris, Kaley Cuoco, Oscar Isaac, Sarah H...</td>\n",
       "      <td>Celebrating Disneys new land that brings Star ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Craig Sechler</td>\n",
       "      <td>Who were the mysterious people who built Machu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stefan Frank</td>\n",
       "      <td>Ancient civilizations shared an incredible kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Julianna Margulies</td>\n",
       "      <td>How will you make the world a better place? He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Angelina Jolie, Elle Fanning, Chiwetel Ejiofor...</td>\n",
       "      <td>The story of Disneys most iconic villain conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carrie Fisher, Mark Hamill, Adam Driver, Daisy...</td>\n",
       "      <td>The landmark Skywalker saga comes to a conclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ed Helms</td>\n",
       "      <td>Steve the penguin embarks on an epic quest to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kristen Bell, Idina Menzel, Josh Gad, Jonathan...</td>\n",
       "      <td>Elsa journeys into the unknown to uncover trut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cast  \\\n",
       "0   James McAvoy, Michael Fassbender, Jennifer Law...   \n",
       "1   Louis Ashbourne Serkis, Tom Taylor, Rebecca Fe...   \n",
       "2                         a-chan , KASHIYUKA , NOCCHi   \n",
       "3                                             YOSHIKI   \n",
       "4                                        Dan Nachtrab   \n",
       "5                     Jeremiah Sullivan, Dave Hoffman   \n",
       "6                                         Bert Morris   \n",
       "7                                         Jay Sanders   \n",
       "8                                      Maite Jauregui   \n",
       "9                                        Loïck Peyron   \n",
       "10                                       Colin Solman   \n",
       "11                                        Paul Bandey   \n",
       "12  Neil Harris, Kaley Cuoco, Oscar Isaac, Sarah H...   \n",
       "13                                      Craig Sechler   \n",
       "14                                       Stefan Frank   \n",
       "15                                 Julianna Margulies   \n",
       "16  Angelina Jolie, Elle Fanning, Chiwetel Ejiofor...   \n",
       "17  Carrie Fisher, Mark Hamill, Adam Driver, Daisy...   \n",
       "18                                           Ed Helms   \n",
       "19  Kristen Bell, Idina Menzel, Josh Gad, Jonathan...   \n",
       "\n",
       "                                          description  \n",
       "0   When Jean Grey transforms into the Dark Phoeni...  \n",
       "1   When a kid discovers the legendary sword, Exca...  \n",
       "2   J-Pop band Perfume shares their passion for mu...  \n",
       "3   Yoshiki from X Japan performs two Disney songs...  \n",
       "4   Great Shark Chow Down – prepare for a feast of...  \n",
       "5   Marine biologist attempts to get bitten by a d...  \n",
       "6   Discover the technical prowess behind Petra, a...  \n",
       "7   National Geographic reconstructs the Ulfberht,...  \n",
       "8   Forensic experts scan Pompeiis victims to inve...  \n",
       "9   Loïck Peyron investigates the 1978 Amoco Cadiz...  \n",
       "10  As we follow the robbers life cycle, we learn ...  \n",
       "11  On April 15, 2019, Paris firefighters gave eve...  \n",
       "12  Celebrating Disneys new land that brings Star ...  \n",
       "13  Who were the mysterious people who built Machu...  \n",
       "14  Ancient civilizations shared an incredible kno...  \n",
       "15  How will you make the world a better place? He...  \n",
       "16  The story of Disneys most iconic villain conti...  \n",
       "17  The landmark Skywalker saga comes to a conclus...  \n",
       "18  Steve the penguin embarks on an epic quest to ...  \n",
       "19  Elsa journeys into the unknown to uncover trut...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film[['cast', 'description']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"C:\\data _cinema\\notebook\\data_cleaned.xlsx\"\n",
    "readme = pd.read_excel(excel_path, sheet_name = \"readme\")\n",
    "ticket = pd.read_excel(excel_path, sheet_name = \"ticket\")\n",
    "\n",
    "# Đọc lại toàn bộ sheet\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    readme.to_excel(writer, sheet_name='readme', index=False)\n",
    "    df.to_excel(writer, sheet_name='customer', index=False)\n",
    "    ticket.to_excel(writer, sheet_name='ticket', index=False)\n",
    "    film.to_excel(writer, sheet_name='film', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07d29025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: đã ghi đè cột 'address' trong sheet 'customer'.\n",
      "                                           address\n",
      "0                P. Hòa Khê, Q. Thanh Khê, Đà Nẵng\n",
      "1                 P. Mân Thái, Q. Sơn Trà, Đà Nẵng\n",
      "2                            H. Quế Sơn, Quảng Nam\n",
      "3           Đường Trường Chinh, Q. Cẩm Lệ, Đà Nẵng\n",
      "4                               Q. Cẩm Lệ, Đà Nẵng\n",
      "...                                            ...\n",
      "4474                                       Đà Nẵng\n",
      "4475              P. Phước Mỹ, Q. Sơn Trà, Đà Nẵng\n",
      "4476                             Nguyen Gian Thanh\n",
      "4477  Đường Ngũ Hành Sơn, Q. Ngũ Hành Sơn, Đà Nẵng\n",
      "4478       P. Thanh Khê Tây, Q. Thanh Khê, Đà Nẵng\n",
      "\n",
      "[4479 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re, unicodedata, difflib, pandas as pd\n",
    "import shutil\n",
    "\n",
    "# ====== CẤU HÌNH ======\n",
    "excel_path = \"data_cleaned.xlsx\"\n",
    "src_sheet  = \"customer\"          # sheet chứa cột address\n",
    "addr_col   = \"address\"           # tên cột địa chỉ\n",
    "DEFAULT_CITY = \"Đà Nẵng\"\n",
    "OVERWRITE_BACKUP = True          # backup file gốc\n",
    "\n",
    "if OVERWRITE_BACKUP:\n",
    "    shutil.copyfile(excel_path, excel_path + \".bak\")\n",
    "\n",
    "# ==== 0) Utils ====\n",
    "def strip_accents(s: str) -> str:\n",
    "    s = unicodedata.normalize('NFKD', str(s))\n",
    "    s = ''.join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.replace('Đ','D').replace('đ','d')\n",
    "\n",
    "def norm_key(s: str) -> str:\n",
    "    s = strip_accents(str(s)).lower()\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def best_match(s, candidates, cutoff=0.86):\n",
    "    if not s: return (None, 0.0)\n",
    "    key = norm_key(s)\n",
    "    keys = list(candidates.keys())\n",
    "    matches = difflib.get_close_matches(key, keys, n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        mk = matches[0]\n",
    "        score = difflib.SequenceMatcher(None, key, mk).ratio()\n",
    "        return (candidates[mk], score)\n",
    "    return (None, 0.0)\n",
    "\n",
    "def clean_street_name(name: str) -> str:\n",
    "    # loại tiền tố Đường/Duong/Đg...\n",
    "    return re.sub(r'^(đường|duong|đg\\.?|dg\\.?)\\s+', '', str(name), flags=re.I).strip()\n",
    "\n",
    "# ==== 1) ĐIỀN THỦ CÔNG TẠI ĐÂY ====\n",
    "# 👉 Bạn tự thêm/sửa danh sách phường & tên đường cho từng quận.\n",
    "#    Mẫu đúng: mỗi quận là 1 key \"Q. Tên Quận\": [ \"Tên 1\", \"Tên 2\", ... ]\n",
    "\n",
    "WARDS_BY_DISTRICT = {\n",
    "    \"Q. Hải Châu\":   [\"Thuận Phước\",\"Thạch Thang\",\"Thanh Bình\",\"Hải Châu I\",\"Hải Châu II\",\n",
    "        \"Phước Ninh\",\"Hòa Thuận Tây\",\"Hòa Thuận Đông\",\"Nam Dương\",\n",
    "        \"Bình Hiên\",\"Bình Thuận\",\"Hòa Cường Bắc\",\"Hòa Cường Nam\"],        # ví dụ\n",
    "    \"Q. Thanh Khê\":  [\"An Khê\",\"Chính Gián\",\"Hòa Khê\",\"Tam Thuận\",\"Tân Chính\",\n",
    "        \"Thạc Gián\",\"Thanh Khê Đông\",\"Thanh Khê Tây\",\"Vĩnh Trung\",\"Xuân Hà\"],\n",
    "    \"Q. Sơn Trà\":    [\"An Hải Bắc\",\"An Hải Đông\",\"An Hải Tây\",\"Mân Thái\",\n",
    "                        \"Nại Hiên Đông\",\"Phước Mỹ\",\"Thọ Quang\"],\n",
    "    \"Q. Ngũ Hành Sơn\": [\"Hòa Hải\",\"Hòa Quý\",\"Khuê Mỹ\",\"Mỹ An\"],\n",
    "    \"Q. Liên Chiểu\": [\"Hòa Hiệp Bắc\",\"Hòa Hiệp Nam\",\"Hòa Khánh Bắc\",\"Hòa Khánh Nam\",\"Hòa Minh\", \"Hòa Khánh\"],\n",
    "    \"Q. Cẩm Lệ\":     [\"Hòa An\",\"Hòa Phát\",\"Hòa Thọ Đông\",\"Hòa Thọ Tây\",\"Hòa Xuân\",\"Khuê Trung\"],\n",
    "}\n",
    "\n",
    "STREETS_BY_DISTRICT = {\n",
    "    \"Q. Hải Châu\": [\n",
    "        \"Lê Duẩn\",\"Quang Trung\",\"Phan Đình Phùng\",\"Trần Phú\",\"Ông Ích Khiêm\",\n",
    "        \"Phan Châu Trinh\",\"Lê Đình Dương\",\"Yên Bái\",\"Nguyễn Chí Thanh\",\n",
    "        \"Hải Phòng\",\"Hùng Vương\",\"Lý Tự Trọng\",\"Thái Phiên\",\"Pasteur\",\n",
    "        \"Phạm Hồng Thái\",\"Triệu Nữ Vương\",\"Bạch Đằng\",\"Duy Tân\",\"2 Tháng 9\",\n",
    "        \"Phạm Ngũ Lão\",\"Thanh Sơn\", \"Lê Duẩn\",\"Quang Trung\",\"Phan Đình Phùng\",\"Trần Phú\",\"Ông Ích Khiêm\",\n",
    "        \"Phan Châu Trinh\",\"Lê Đình Dương\",\"Yên Bái\",\"Nguyễn Chí Thanh\",\n",
    "        \"Hải Phòng\",\"Hùng Vương\",\"Lý Tự Trọng\",\"Thái Phiên\",\"Pasteur\",\n",
    "        \"Phạm Hồng Thái\",\"Triệu Nữ Vương\",\"Bạch Đằng\",\"Duy Tân\",\"2 Tháng 9\",\n",
    "        \"Phạm Ngũ Lão\",\"Thanh Sơn\", \"Nguyễn Văn Linh\",\"Hoàng Diệu\",\"Phan Bội Châu\",\"Trần Quốc Toản\",\"Lê Lợi\",\"Nguyễn Du\",\"Đống Đa\",\n",
    "        \"Chu Văn An\",\"Huỳnh Thúc Kháng\",\"Ngô Gia Tự\",\"Lý Thường Kiệt\",\"Nguyễn Trãi\",\n",
    "        \"Hồ Tùng Mậu\",\"Nguyễn Thành Hãn\",\"Cô Giang\",\"Phạm Đình Hổ\",\"Yên Bái\",\n",
    "        \"Cao Thắng\",\"Đào Duy Từ\",\"Bùi Viện\",\"Trần Bình Trọng\"\n",
    "    ],\n",
    "    \"Q. Thanh Khê\": [\n",
    "        \"Điện Biên Phủ\",\"Thái Thị Bôi\",\"Lê Độ\",\"Nguyễn Phước Nguyên\",\"Trần Cao Vân\",\n",
    "        \"Nguyễn Tri Phương\",\"Trưng Nữ Vương\",\"Nguyễn Hoàng\",\"Hà Huy Tập\",\"Hàm Nghi\",\n",
    "        \"Cù Chính Lan\",\"Phan Thanh\",\"Huỳnh Ngọc Huệ\",\"Trần Xuân Lê\",\"Đỗ Quang\",\n",
    "        \"Lý Thái Tổ\",\"Yên Khê\", \"Hoàng Hoa Thám\",\"Kỳ Đồng\",\"Võ Văn Tần\",\"Phạm Nhữ Tăng\",\n",
    "        \"Phạm Văn Nghị\",\"Lê Duy Đình\",\"Nguyễn Văn Huề\",\"Nguyễn Chánh\"\n",
    "    ],\n",
    "    \"Q. Sơn Trà\": [\n",
    "        \"Trần Hưng Đạo\",\"Yết Kiêu\",\"Ngô Quyền\",\"Chu Huy Mân\",\"Hồ Nghinh\",\n",
    "        \"Hoàng Sa\",\"Võ Văn Kiệt\",\"Nguyễn Công Trứ\",\"Dương Vân Nga\",\"Lê Tấn Trung\",\n",
    "        \"Trần Nhân Tông\",\"Phạm Cự Lượng\",\"Phạm Văn Đồng\",\"Giáp Văn Cương\",\n",
    "        \"An Đồn\",\"Mân Quang\",\"Lê Hữu Trác\",\"Hoàng Đức Lương\",\n",
    "        \"Ngọc Hân\",\"Phan Kế Bính\",\"Phùng Chí Kiên\"\n",
    "    ],\n",
    "    \"Q. Ngũ Hành Sơn\": [\n",
    "        \"Lê Văn Hiến\",\"Nguyễn Văn Thoại\",\"Trần Đại Nghĩa\",\"Minh Mạng\",\n",
    "        \"Lê Quang Đạo\",\"Hồ Xuân Hương\",\"Nghiêm Xuân Yêm\",\"Võ Chí Công\",\n",
    "        \"Trường Sa\",\"Ngũ Hành Sơn\",\"Võ Nguyên Giáp\", \"Lạc Long Quân\",\"Triệu Việt Vương\",\"Hải Sơn\",\"Phan Huy Ôn\",\n",
    "        \"Mai An\",\"Thế Lữ\",\"Vũ Quỳnh\"\n",
    "    ],\n",
    "    \"Q. Liên Chiểu\": [\n",
    "        \"Nguyễn Lương Bằng\",\"Tôn Đức Thắng\",\"Hoàng Văn Thái\",\"Nguyễn Tất Thành\",\n",
    "        \"Kinh Dương Vương\",\"Nam Cao\",\"Bắc Đẩu\",\"Bàu Tràm\",\n",
    "        \"Phạm Như Xương\",\"Âu Cơ\",\"Lê Ngô Cát\",\"Lê Văn Long\",\n",
    "        \"Phạm Khu Tiết\",\"Nguyễn Đình Tựu\", \"Hoàng Tăng Bí\",\"Nguyễn Văn Cừ\",\"Ung Văn Khiêm\",\"Lê Thiệt\",\n",
    "        \"Nguyễn Cảnh Dị\",\"Tô Hiệu\",\"Văn Cao\",\"Nguyễn Huy Tưởng\"\n",
    "    ],\n",
    "    \"Q. Cẩm Lệ\": [\n",
    "        \"Tôn Đản\",\"Trần Nam Trung\",\"Phạm Hữu Kính\",\"Cách Mạng Tháng 8\",\"Tiểu La\",\n",
    "        \"Trường Chinh\",\"Đoàn Nhữ Hài\",\"Đinh Tiên Hoàng\",\"Thăng Long\",\"Phạm Phú Thứ\", \"Lê Trọng Tấn\",\"Tôn Thất Tùng\",\"Ông Ích Đường\",\"Đỗ Huy Uyển\",\n",
    "        \"Nguyễn Nghiêm\",\"Trường Sơn\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# (tuỳ chọn) alias chính tả\n",
    "WARD_ALIAS = {\n",
    "    norm_key(\"Hoa Khe\"): \"Hòa Khê\",\n",
    "}\n",
    "STREET_ALIAS = {\n",
    "    norm_key(\"Trung Nữ Vương\"): \"Trưng Nữ Vương\",\n",
    "    norm_key(\"Duong Nguyen Van Linh\"): \"Nguyễn Văn Linh\",\n",
    "}\n",
    "\n",
    "# ==== 2) Sinh map dùng cho matching ====\n",
    "# District map (quận/huyện/tỉnh lân cận để nhận diện nếu người dùng đã ghi sẵn)\n",
    "districts_dn = [\"Hải Châu\",\"Thanh Khê\",\"Sơn Trà\",\"Ngũ Hành Sơn\",\"Liên Chiểu\",\"Cẩm Lệ\",\"Hòa Vang\",\"Hoàng Sa\"]\n",
    "districts_qn = [\"Quế Sơn\",\"Điện Bàn\",\"Duy Xuyên\",\"Thăng Bình\",\"Núi Thành\"]\n",
    "\n",
    "district_map = { norm_key(d): f\"Q. {d}\" for d in districts_dn if d not in [\"Hòa Vang\",\"Hoàng Sa\"] }\n",
    "district_map.update({ norm_key(\"Hòa Vang\"): \"H. Hòa Vang\", norm_key(\"Hoàng Sa\"): \"H. Hoàng Sa\" })\n",
    "district_map.update({ norm_key(d): f\"H. {d}\" for d in districts_qn })\n",
    "\n",
    "# Ward maps\n",
    "ward_map, ward_district_map = {}, {}\n",
    "for dist, names in WARDS_BY_DISTRICT.items():\n",
    "    for raw in names:\n",
    "        name = WARD_ALIAS.get(norm_key(raw), raw)\n",
    "        k = norm_key(name)\n",
    "        ward_map[k] = f\"P. {name}\"\n",
    "        ward_district_map[k] = dist\n",
    "\n",
    "# Street maps\n",
    "street_map, street_district_map = {}, {}\n",
    "for dist, names in STREETS_BY_DISTRICT.items():\n",
    "    for raw in names:\n",
    "        name = STREET_ALIAS.get(norm_key(raw), clean_street_name(raw))\n",
    "        k = norm_key(name)\n",
    "        street_map[k] = f\"Đường {name}\"\n",
    "        street_district_map.setdefault(k, dist)\n",
    "\n",
    "# Tên TP viết tắt\n",
    "city_map = {\n",
    "    norm_key(\"Đà Nẵng\"): \"Đà Nẵng\",\n",
    "    norm_key(\"DN\"): \"Đà Nẵng\",\n",
    "    norm_key(\"Da Nang\"): \"Đà Nẵng\",\n",
    "    norm_key(\"Quảng Nam\"): \"Quảng Nam\",\n",
    "    norm_key(\"QN\"): \"Quảng Nam\",\n",
    "}\n",
    "\n",
    "# ==== 3) Chuẩn hoá 1 địa chỉ ====\n",
    "def normalize_address(raw: str, cutoff=0.86):\n",
    "    if pd.isna(raw) or str(raw).strip()==\"\":\n",
    "        return {\"address_clean\": None, \"street\":None,\"ward\":None,\"district\":None,\"city\":None,\"status\":\"empty\"}\n",
    "\n",
    "    s = str(raw)\n",
    "    s = unicodedata.normalize('NFC', s).replace('\\u00A0',' ')\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    key = norm_key(s)\n",
    "\n",
    "    # Nhận diện TP nhanh\n",
    "    city = None\n",
    "    for k, canon in city_map.items():\n",
    "        if k in key:\n",
    "            city = canon\n",
    "            break\n",
    "    if city is None and re.search(r'(,|\\s)\\b(dn|đn)\\b$', key):\n",
    "        city = \"Đà Nẵng\"\n",
    "\n",
    "    # N-grams 1..3\n",
    "    tokens = key.split()\n",
    "    ngrams = set(' '.join(tokens[i:i+n]) for n in (1,2,3) for i in range(len(tokens)-n+1))\n",
    "\n",
    "    # Fuzzy match\n",
    "    w_best = max((best_match(g, ward_map, cutoff)     for g in ngrams), key=lambda x: x[1], default=(None,0))\n",
    "    d_best = max((best_match(g, district_map, cutoff) for g in ngrams), key=lambda x: x[1], default=(None,0))\n",
    "    s_best = max((best_match(g, street_map, cutoff)   for g in ngrams), key=lambda x: x[1], default=(None,0))\n",
    "    ward, w_score = w_best\n",
    "    district, d_score = d_best\n",
    "    street, s_score = s_best\n",
    "\n",
    "    # Suy luận từ phường\n",
    "    if city is None and ward:\n",
    "        city = DEFAULT_CITY\n",
    "    if district is None and ward:\n",
    "        if not hasattr(normalize_address, \"_ward_key_by_label\"):\n",
    "            normalize_address._ward_key_by_label = {v: k for k, v in ward_map.items()}\n",
    "        wkey = normalize_address._ward_key_by_label.get(ward)\n",
    "        if wkey in ward_district_map:\n",
    "            district = ward_district_map[wkey]\n",
    "\n",
    "    # Suy luận từ đường\n",
    "    if city is None and street:\n",
    "        city = DEFAULT_CITY\n",
    "    if district is None and street:\n",
    "        if not hasattr(normalize_address, \"_street_key_by_label\"):\n",
    "            normalize_address._street_key_by_label = {v: k for k, v in street_map.items()}\n",
    "        skey = normalize_address._street_key_by_label.get(street)\n",
    "        if skey in street_district_map:\n",
    "            district = street_district_map[skey]\n",
    "\n",
    "    # Suy city từ loại district\n",
    "    if city is None:\n",
    "        if district and district.startswith(\"Q.\"):\n",
    "            city = \"Đà Nẵng\"\n",
    "        elif district and district.startswith(\"H. Quế Sơn\"):\n",
    "            city = \"Quảng Nam\"\n",
    "\n",
    "    parts = [p for p in [street, ward, district, city] if p]\n",
    "    addr_clean = ', '.join(parts) if parts else s.title()\n",
    "\n",
    "    status = \"ok\"\n",
    "    flags = []\n",
    "    if s_score < cutoff and street:   flags.append(\"street_low_conf\")\n",
    "    if w_score < cutoff and ward:     flags.append(\"ward_low_conf\")\n",
    "    if d_score < cutoff and district: flags.append(\"district_low_conf\")\n",
    "    if not (street or ward or district or city): flags.append(\"no_match\")\n",
    "    if flags: status = \";\".join(flags)\n",
    "\n",
    "    return {\"address_clean\": addr_clean, \"street\": street, \"ward\": ward,\n",
    "            \"district\": district, \"city\": city, \"status\": status}\n",
    "\n",
    "# ==== 4) ÁP DỤNG & GHI FILE ====\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "if src_sheet not in sheets:\n",
    "    raise KeyError(f\"Không tìm thấy sheet '{src_sheet}'.\")\n",
    "df_cus = sheets[src_sheet].copy()\n",
    "\n",
    "if addr_col not in df_cus.columns:\n",
    "    raise KeyError(f\"Sheet '{src_sheet}' không có cột '{addr_col}'. Columns: {list(df_cus.columns)}\")\n",
    "\n",
    "res = df_cus[addr_col].apply(normalize_address).apply(pd.Series)\n",
    "df_cus[addr_col] = res[\"address_clean\"]\n",
    "# df_cus[\"status\"] = res[\"status\"]   # mở nếu muốn soát lỗi\n",
    "\n",
    "# Xoá cột phụ nếu từng tồn tại\n",
    "for c in [\"address_clean\",\"street\",\"ward\",\"district\",\"city\"]:\n",
    "    if c in df_cus.columns:\n",
    "        df_cus.drop(columns=[c], inplace=True)\n",
    "\n",
    "sheets[src_sheet] = df_cus\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as w:\n",
    "    for name, dfi in sheets.items():\n",
    "        dfi.to_excel(w, sheet_name=name, index=False)\n",
    "\n",
    "print(\"Done: đã ghi đè cột 'address' trong sheet 'customer'.\")\n",
    "print(df_cus[[addr_col]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
